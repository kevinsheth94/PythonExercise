{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa931368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kevin.sheth.saama.co\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install required libraries\n",
    "pip install pandas numpy psycopg2-binary sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError, errorcodes, errors\n",
    "import psycopg2.extras as extras\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f98cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.testing' has no attribute 'rands_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-757440745356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create a dataframe of 15 columns and 10 million rows with random numbers and strings. Export it to CSV format which comes around ~1 GB in size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m99999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m99999999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'C1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C9'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C11'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C12'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C13'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C14'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'C15'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrands_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"huge_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.testing' has no attribute 'rands_array'"
     ]
    }
   ],
   "source": [
    "#Create a dataframe of 15 columns and 10 million rows with random numbers and strings. Export it to CSV format which comes around ~1 GB in size.\n",
    "df = pd.DataFrame(data=np.random.randint(99999, 99999999, size=(10000000,14)),columns=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14'])\n",
    "df['C15'] = pd.util.testing.rands_array(5,10000000)\n",
    "df.to_csv(\"huge_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0909a4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read in chunks:  0.26674938201904297 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#read data in chunks of 10000 rows at a time. This will reduce time and ram. \n",
    "#The chunksize can be increased if there is more ram to improve performance time or decreased if the ram restrictions still apply.\n",
    "df = pd.read_csv('huge_data.csv',chunksize=10000)\n",
    "end = time.time()\n",
    "print(\"Time taken to read in chunks: \",(end-start),\"sec\")\n",
    "pd_df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6074b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that handles and parses psycopg2 exceptions\n",
    "def show_psycopg2_exception(err):\n",
    "    # get details about the exception\n",
    "    err_type, err_obj, traceback = sys.exc_info()    \n",
    "    # get the line number when exception occured\n",
    "    line_n = traceback.tb_lineno    \n",
    "    # print the connect() error\n",
    "    print (\"\\npsycopg2 ERROR:\", err, \"on line number:\", line_n)\n",
    "    print (\"psycopg2 traceback:\", traceback, \"-- type:\", err_type) \n",
    "    # psycopg2 extensions.Diagnostics object attribute\n",
    "    print (\"\\nextensions.Diagnostics:\", err.diag)    \n",
    "    # print the pgcode and pgerror exceptions\n",
    "    print (\"pgerror:\", err.pgerror)\n",
    "    print (\"pgcode:\", err.pgcode, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d2de956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL...........\n",
      "Connection successfully..................\n"
     ]
    }
   ],
   "source": [
    "# Postgres username, password, and database name\n",
    "POSTGRES_ADDRESS = 'localhost'\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_USERNAME = 'postgres'\n",
    "POSTGRES_PASSWORD = 'kevin' \n",
    "POSTGRES_DBNAME = 'postgres'\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'\n",
    "                .format(username=POSTGRES_USERNAME,\n",
    "                        password=POSTGRES_PASSWORD,\n",
    "                        ipaddress=POSTGRES_ADDRESS,\n",
    "                        port=POSTGRES_PORT,\n",
    "                        dbname=POSTGRES_DBNAME))\n",
    "# Create the connection to postgres db\n",
    "try:\n",
    "    print('Connecting to the PostgreSQL...........')\n",
    "    cnx = create_engine(postgres_str)\n",
    "    print(\"Connection successfully..................\")\n",
    "except OperationalError as err:\n",
    "    # passing exception to function\n",
    "    show_psycopg2_exception(err)        \n",
    "    # set the connection to 'None' in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd9220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_sql duration: 647.5341262817383 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "try:\n",
    "    #using connection created, push the data in public.test_od in chunksizes of 10000. \n",
    "    #This can be adjusted too similar to the import from csv to improve performance time or to adjust for ram restrictions\n",
    "    pd_df.to_sql('public.test_od', con=cnx, if_exists='replace', index=False, chunksize=100000)\n",
    "    print(\"to_sql duration: {} seconds\".format(time.time() - start_time))\n",
    "except OperationalError as err:\n",
    "    # passing exception to function\n",
    "    show_psycopg2_exception(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d81d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities with more than 1 visits:\n",
      "SFO\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "   database=POSTGRES_DBNAME, user=POSTGRES_USERNAME, password=POSTGRES_PASSWORD, host=POSTGRES_ADDRESS, port= POSTGRES_PORT\n",
    ")\n",
    "#1) Cities frequently visited?\n",
    "\n",
    "sql='''select v.city_id_visited,\n",
    "            trim(c.city_name) as city_name,\n",
    "            count(distinct customer_id) as count \n",
    "            from visits v \n",
    "            join city c on c.city_id=v.city_id_visited \n",
    "            group by v.city_id_visited,c.city_name \n",
    "            having count(distinct customer_id)>1'''\n",
    "cursor.execute(sql)\n",
    "output1=cursor.fetchall()\n",
    "print(\"Cities with more than 1 visits:\")\n",
    "for row in output1:\n",
    "    print(row[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
